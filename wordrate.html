<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Word Rate Features - LITCoder</title>
    <link rel="stylesheet" href="styles/main.css">
    <link rel="stylesheet" href="styles/tutorials.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css">
</head>
<body>
    <div class="container">
        <nav class="nav">
            <a href="index.html" class="nav-logo">LITCoder</a>
            <div class="nav-links">
                <a href="index.html">Home</a>
                <a href="tutorials.html">Tutorials</a>
                <a href="https://arxiv.org/abs/2509.09152" target="_blank">Paper</a>
                <a href="https://github.com/GT-LIT-Lab/litcoder_core" target="_blank">GitHub</a>
            </div>
        </nav>

        <header class="tutorial-header">
            <h1>Word Rate Feature Tutorial</h1>
            <p>This tutorial shows how to train encoding models using word rate features with the LeBel assembly. Word rate features are simple but effective baselines that measure the rate of word presentation.</p>
        </header>

        <section class="tutorial-section">
            <h2>Overview</h2>
            <p>Word rate features capture the temporal dynamics of language presentation by measuring how many words are presented per time unit. This is one of the simplest but an effective feature for brain encoding models.</p>
        </section>

        <section class="tutorial-section">
            <h2>Key Components</h2>
            <ul>
                <li><strong>Assembly</strong>: Pre-packaged LeBel assembly containing brain data and stimuli</li>
                <li><strong>Feature Extractor</strong>: WordRateFeatureExtractor for computing word presentation rates</li>
                <li><strong>Downsampler</strong>: Aligns word-level features with brain data timing</li>
                <li><strong>Model</strong>: Ridge regression with nested cross-validation</li>
                <li><strong>Trainer</strong>: AbstractTrainer orchestrates the entire pipeline</li>
            </ul>
        </section>

        <section class="tutorial-section">
            <h2>Step-by-Step Tutorial</h2>

            <h3>1. Load the Assembly</h3>
            <pre class="code-block"><code class="language-python">from encoding.assembly.assembly_loader import load_assembly

# Load the pre-packaged LeBel assembly
assembly = load_assembly("assembly_lebel_uts03.pkl")</code></pre>

            <h3>2. Create Word Rate Feature Extractor</h3>
            <pre class="code-block"><code class="language-python">from encoding.features.factory import FeatureExtractorFactory

extractor = FeatureExtractorFactory.create_extractor(
    modality="wordrate",
    model_name="wordrate",
    config={},
    cache_dir="cache",
)</code></pre>

            <h3>3. Set Up Downsampler and Model</h3>
            <pre class="code-block"><code class="language-python">from encoding.downsample.downsampling import Downsampler
from encoding.models.nested_cv import NestedCVModel

downsampler = Downsampler()
model = NestedCVModel(model_name="ridge_regression")</code></pre>

            <h3>4. Configure Training Parameters</h3>
            <pre class="code-block"><code class="language-python"># FIR delays for hemodynamic response modeling
fir_delays = [1, 2, 3, 4]

# Trimming configuration for LeBel dataset
trimming_config = {
    "train_features_start": 10,
    "train_features_end": -5,
    "train_targets_start": 0,
    "train_targets_end": None,
    "test_features_start": 50,
    "test_features_end": -5,
    "test_targets_start": 40,
    "test_targets_end": None,
}

downsample_config = {}</code></pre>

            <h3>5. Create and Run Trainer</h3>
            <pre class="code-block"><code class="language-python">from encoding.trainer import AbstractTrainer

trainer = AbstractTrainer(
    assembly=assembly,
    feature_extractors=[extractor],
    downsampler=downsampler,
    model=model,
    fir_delays=fir_delays,
    trimming_config=trimming_config,
    use_train_test_split=True,
    logger_backend="wandb",
    wandb_project_name="lebel-wordrate",
    dataset_type="lebel",
    results_dir="results",
    downsample_config=downsample_config,
)

metrics = trainer.train()
print(f"Median correlation: {metrics.get('median_score', float('nan')):.4f}")</code></pre>
        </section>

        <section class="tutorial-section">
            <h2>Understanding Word Rate Features</h2>
            <ol>
                <li><strong>Counting words per TR</strong>: The assembly pre-computes word rates for each TR</li>
                <li><strong>No additional processing needed</strong>: Word rates are already aligned with brain data</li>
                <li><strong>Simple but effective</strong>: Captures temporal dynamics of language presentation</li>
            </ol>
            <p>The word rate extractor simply returns the pre-computed word rates from the assembly, making it the fastest feature type to compute.</p>
        </section>

        <section class="tutorial-section">
            <h2>Key Parameters</h2>
            <ul>
                <li><code>modality</code>: "wordrate" - specifies the feature type</li>
                <li><code>model_name</code>: "wordrate" - identifier for the extractor</li>
                <li><code>config</code>: {} - no additional configuration needed</li>
                <li><code>cache_dir</code>: "cache" - directory for caching (though word rates don't need caching)</li>
            </ul>
        </section>

        <section class="tutorial-section">
            <h2>Training Configuration</h2>
            <ul>
                <li><code>fir_delays</code>: [1, 2, 3, 4] - temporal delays to account for hemodynamic response</li>
                <li><code>trimming_config</code>: LeBel-specific trimming to avoid boundary effects</li>
            </ul>
        </section>

        <footer class="footer">
            <div>© 2025 LITCoder Project — Georgia Tech</div>
            <div style="font-size: 0.8rem; margin-top: 4px;">Authors: Taha Binhuraib, Ruimin Gao, Anna A. Ivanova</div>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html> 